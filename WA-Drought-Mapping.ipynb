{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "088c9b3b",
   "metadata": {},
   "source": [
    "## Mapping drought in WA\n",
    "##### update these details for your code\n",
    "Author:  Stanley Mastrantonis\n",
    "\n",
    "Date: \n",
    "\n",
    "version 1 python 3, written in ESRI ArcPro v2.9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0a024b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mapping drought in WA\n",
    "  \n",
    "We will use this data to map the BoM definition of drought across WA for a set time period.  The BoM definition of drought refers to a year of total rainfall below the 10th percentile for the history of data. \n",
    "\n",
    "What is a data cube and arrays: \n",
    "\n",
    "![data cube](https://docs.xarray.dev/en/stable/_static/dataset-diagram-logo.png)\n",
    "\n",
    "Data cubes are multi-dimensional extensions of two-dimensional tables.\n",
    "\n",
    "A data cube can be thought of as a set of similar 2D tables stacked on top of each other. For example, a set of 2D tables showing population at 30 June by age group for each local government area would form a data cube, with local government area as the third dimension.\n",
    "\n",
    "What is gdal:\n",
    "\n",
    "![gdal](https://gdal.org/_images/OSGeo_project.png)\n",
    "\n",
    "GDAL is a C/C++/Python translator library for more than 200 raster and vector geospatial data formats. \n",
    "\n",
    "gdal instances or bindings are used by almost all spatial software, and provide the functions for projecting data between CRSs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e75428f",
   "metadata": {},
   "source": [
    "## Libraries and modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "973633a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib, urllib.request\n",
    "import xarray\n",
    "from osgeo import gdal, gdalconst, osr\n",
    "import os, copy, math, glob\n",
    "import arcpy #ESRI\n",
    "from arcgis.gis import GIS #ESRI \n",
    "gis = GIS('pro')\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6c96b2",
   "metadata": {},
   "source": [
    "## Functions \n",
    "read in the functions from the py script or the below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e21f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Drought_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "832b89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskarray(file: str, xmin: float, xmax: float, ymin: float, ymax: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Masks an xarray dataset based on longitude and latitude ranges and returns the sum of values along the 'time' dimension.\n",
    "    \n",
    "    Args:\n",
    "        file (str): File path to the xarray dataset.\n",
    "        xmin (float): Minimum longitude value for masking.\n",
    "        xmax (float): Maximum longitude value for masking.\n",
    "        ymin (float): Minimum latitude value for masking.\n",
    "        ymax (float): Maximum latitude value for masking.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Numpy array containing the sum of values after masking along the 'time' dimension.\n",
    "    \"\"\"\n",
    "    xds_i = xr.open_dataset(file)\n",
    "    mask_lon_i = (xds_i.lon >= xmin) & (xds_i.lon <= xmax)\n",
    "    mask_lat_i = (xds_i.lat >= ymin) & (xds_i.lat <= ymax)\n",
    "    clipped_i = xds_i.where(mask_lon_i & mask_lat_i, drop=True)\n",
    "    xds_i_sum = clipped_i.sum(skipna=True, dim='time').drop_vars(names='crs', errors='ignore')\n",
    "    \n",
    "    nparr = xds_i_sum.to_array().values                     \n",
    "    return nparr\n",
    "\n",
    "def arrToRast(np_arr: np.ndarray, res: float, display: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Creates a raster from a numpy array using arcpy.\n",
    "\n",
    "    Args:\n",
    "        np_arr (np.ndarray): Numpy array to be converted to a raster.\n",
    "        res (float): Resolution of the raster.\n",
    "        display (bool, optional): Flag to add the output raster to the map display. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    wgs = arcpy.SpatialReference('WGS 1984')  # create an arcpy spatial reference\n",
    "    arcpy.env.addOutputsToMap = display\n",
    "    rast_arr = arcpy.NumPyArrayToRaster(np_arr, ll, res, res, 0)  # convert numpy array to arcpy raster\n",
    "\n",
    "    arcpy.management.DefineProjection(rast_arr, wgs)  # set the coordinate reference system (CRS) of the new raster\n",
    "\n",
    "    if 'rain' in str(os.getcwd()).lower():\n",
    "        nm = '_Rain.tif'\n",
    "    else:\n",
    "        nm = '_Drought.tif'\n",
    "    rast_arr.save(os.path.join(os.getcwd(), mt_i + nm))  # save the raster\n",
    "    del rast_arr\n",
    "\n",
    "def flipyflip(nparr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Flips a numpy array twice.\n",
    "\n",
    "    Args:\n",
    "        nparr (np.ndarray): Numpy array to be flipped.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Flipped numpy array.\n",
    "    \"\"\"\n",
    "    np_xarr_fl = np.flip(np.flip(nparr, 2), 2)\n",
    "    return np_xarr_fl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9741e1d3",
   "metadata": {},
   "source": [
    "## Folder structure\n",
    "The following code will create a folder structure in a working folder for wherever the 'cwd' variable is set to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de0d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = '' #Change this to your working directory\n",
    "datdir = os.path.join(cwd, 'Data')\n",
    "datfolds = os.path.join(datdir, 'Creation')\n",
    "\n",
    "if os.path.exists(datdir): \n",
    "        pass \n",
    "else: \n",
    "        os.mkdir(datdir)\n",
    "\n",
    "if os.path.exists(datfolds): \n",
    "        pass \n",
    "else: \n",
    "        os.mkdir(datfolds)\n",
    "\n",
    "folders = ['netCDF','rasters','shapefiles','Arcpyenv', 'WA' ]\n",
    "\n",
    "for folder in folders:\n",
    "    if os.path.exists(os.path.join(datfolds, folder)): \n",
    "        pass \n",
    "    else: \n",
    "        os.mkdir(os.path.join(datfolds, folder))\n",
    "        \n",
    "rastout = os.path.join(datfolds, 'rasters')        \n",
    "rast_folds = ['rain','stack','drought','severe drought','scratch']\n",
    "\n",
    "for folder in rast_folds:\n",
    "    if os.path.exists(os.path.join(rastout, folder)): \n",
    "        pass \n",
    "    else: \n",
    "        os.mkdir(os.path.join(rastout, folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arcpy environment changes\n",
    "arcpy.env.workspace = os.path.join(datfolds, 'Arcpyenv')\n",
    "arcpy.env.overwriteOutput = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04183610",
   "metadata": {},
   "source": [
    "## Read in the WA shapefile and set create a WGS84 crs \n",
    "\n",
    "Make sure you move the WA shapefile to the correct folder (\"WA\") in your newly created Data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfb4bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = os.path.join(datfolds, 'WA\\\\WA_gcs.shp')\n",
    "sr = arcpy.SpatialReference(\"WGS 1984\")\n",
    "arcpy.management.DefineProjection(roi, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1855f65",
   "metadata": {},
   "source": [
    "## Extracting extents of WA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bcdc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = arcpy.Describe(roi).extent\n",
    "ll = extent.lowerLeft # we need the origin point of the bounding layer (WA) to build rasters later on\n",
    "print (extent) \n",
    "xmin = extent.XMin\n",
    "xmax = extent.XMax\n",
    "ymin = extent.YMin\n",
    "ymax = extent.YMax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7256fdc0",
   "metadata": {},
   "source": [
    "## What is an AWS server bucket?\n",
    "For us, it's a url. Run the below code to inspect the SILO AWS bucket and its content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be1ffb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src='https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/index.html' width=\"1200\" height=\"1000\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src='https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/index.html' width=\"1200\" height=\"1000\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a9b7c6",
   "metadata": {},
   "source": [
    "## Specify a year range\n",
    "We need to specify a time period to collect data from the AWS bucket.\n",
    "For now lets do 10 years of data. You can try for the whole period of data, but just remember it still takes time to download and convert every file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222160dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_range = list(range(2010,2021,1))\n",
    "print(year_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4dff7e",
   "metadata": {},
   "source": [
    "## Download and convert the SILO rainfall data\n",
    "The following code will query and request the specified nc files. nc files are NetCDF files which are data cubes. \n",
    "The nc files have data for all of Australia and we will mask this data for WA.\n",
    "The code will convert the nc files into an xarray dataset. We will then mask the xarray array with the function maskarray called above. How is it masking the xarray array?\n",
    "The code will also convert the xarray array to to a numpy array and then to a raster with the arrToRast function.\n",
    "The arrToRast function was called above and relies on the arpcy NumPyArrayToRaster function. We will learn how to convert an array to a raster with gdal later.\n",
    "\n",
    "Note: if for some reason the SILO data will not download, the nc files have been provided for you and you can skip to the next cell to convert the nc files to rasters\n",
    "\n",
    "Please note that it can take some time to download all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc771e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(year_range), 1):\n",
    "    mt_i = str(year_range[i])\n",
    "    rain_i = 'https://s3-ap-southeast-2.amazonaws.com/silo-open-data/Official/annual/monthly_rain/'+mt_i+'.monthly_rain.nc' \n",
    "    #we are querying every year of data between our year range\n",
    "    print(rain_i)\n",
    "    rain_i_file = os.path.join(datdir, 'Creation//netCDF') + '//Rain_'+mt_i+'.nc'\n",
    "    if os.path.isfile(rain_i_file): \n",
    "        os.remove(rain_i_file)\n",
    "        urllib.request.urlretrieve(rain_i, rain_i_file)\n",
    "    else:\n",
    "        urllib.request.urlretrieve(rain_i, rain_i_file)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e435356b",
   "metadata": {},
   "source": [
    "The below cell will mask the nc files to WA and convert them to raster files.\n",
    "The raster files will be saved in the rain folder under the rasters directory. Temporary raster files will also be added to the map. You can disable this in the arrToRast function by changing the display argument to False. \n",
    "\n",
    "You will notice that the rasters are the wrong way around. This often happens with array data and you will need to find a solution:\n",
    "\n",
    "Hint: search for numpy.flip in the API documentation\n",
    "The answers have also been provided in the answers Notebook. \n",
    "\n",
    "Be sure to remove the temporary rasters from your contents pane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncfiles = glob.glob(os.path.join(datdir, 'Creation//netCDF//*.nc')) \n",
    "os.chdir(os.path.join(rastout, 'rain'))\n",
    "\n",
    "for i in range(0, len(year_range), 1):\n",
    "    mt_i = str(year_range[i])\n",
    "    nc_file = ncfiles[i]\n",
    "    marray = maskarray(nc_file)#maskthe array\n",
    "    arrToRast(marray, 0.05, display = True) # create a raster from the array\n",
    "\n",
    "\n",
    "del marray\n",
    "os.chdir(cwd)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18126e5",
   "metadata": {},
   "source": [
    "## Sense check you results\n",
    "Below is a link to BoM drought average maps. Do your results look similar?\n",
    "Again, your raster may be the wrong way around\n",
    "Hint: lookup the numpy.flip() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09ffe06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src='http://www.bom.gov.au/climate/averages/climatology/rainfall/hires_rn/aus/rnozan.png' width=\"1000\" height=\"800\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src='http://www.bom.gov.au/climate/averages/climatology/rainfall/hires_rn/aus/rnozan.png' width=\"1000\" height=\"800\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0af0fd8",
   "metadata": {},
   "source": [
    "## Calculating percentiles and exporting a raster file with gdal\n",
    "Now that we have several years of rainfall data in raster (.tif) format, we can calculate the 10th percentile of all the data using gdal and numpy.\n",
    "We then use gdal to save the percentile array as a raster file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(os.path.join(rastout, 'rain\\\\*.tif')) # This will list all files of a certain type in a folder\n",
    "array_list = [] #create an empty list to store our arrays\n",
    "\n",
    "\n",
    "gsrc = gdal.Open(filenames[1]) #open a single raster to extract its attributes\n",
    "geotransform = gsrc.GetGeoTransform() \n",
    "projection = gsrc.GetProjectionRef()\n",
    "    \n",
    "for file in filenames:\n",
    "    src = gdal.Open(file)\n",
    "    array_list.append(src.ReadAsArray()) #we will append the raster values as numpy arrays to the array_list\n",
    "\n",
    "    \n",
    "stacked_array = np.stack(array_list) #Here, we stack all the arrays into a multidientional numpy array \n",
    "decile_arr = np.percentile(stacked_array, q = 10, axis = 0) # We calculate the 10th percentile for the raster stack\n",
    "\n",
    "\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "rows, cols = decile_arr.shape\n",
    "perc = driver.Create(os.path.join(rastout,'stack\\\\Percentile.tif'),\n",
    "                        cols, rows, 1,\n",
    "                        gdal.GDT_Float32)\n",
    "\n",
    "perc.SetGeoTransform(geotransform)\n",
    "perc.SetProjection(projection)\n",
    "perc.WriteArray(decile_arr)\n",
    "perc.GetRasterBand(1).SetNoDataValue(0)\n",
    "\n",
    "stats = perc.GetRasterBand(1).GetStatistics(0,1)\n",
    "perc.FlushCache()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(decile_arr, interpolation = 'nearest')\n",
    "plt.show()\n",
    "\n",
    "del perc, stacked_array, array_list, src, gsrc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60807eb7",
   "metadata": {},
   "source": [
    "lets look at some summary statistics for the 10th percentile raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269138af",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dict = {'Max': str(stats[1]), 'Mean': str(stats[2]),\n",
    "              'Min': str(stats[0]), 'STDEV' : str(stats[3])}\n",
    "print(stats_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aae6027",
   "metadata": {},
   "source": [
    "Here, we are classifying every year of the rainfall data as drought if it falls below the 10th percentile threshold for any point in space.\n",
    "\n",
    "The classified rasters (1 for drought) will be saved in the drought folder in the \n",
    "rasters directory\n",
    "\n",
    "If you do not want the temporary rasters to be displayed change the display argument to false in the arrToRast function\n",
    "\n",
    "Note that because we are classifying drought on the same period we are calculating the percentile, all of WA will be in drought at least once out of the 10 year period. Ideally, you would calculate the percentile for the entire period of data and classify a defined period (BoM suggests 40 years).\n",
    "\n",
    "You can of course try for a longer time frame, but for now we will stick to 10 years for the purposes of the lesson. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(rastout, 'drought'))\n",
    "drought_arr = []\n",
    "\n",
    "psrc = gdal.Open(os.path.join(rastout+'\\\\stack\\\\Percentile.tif'))\\\n",
    "            .ReadAsArray()\n",
    "\n",
    "for i, file in enumerate(filenames):\n",
    "    mt_i = str(year_range[i])\n",
    "    rainarr = gdal.Open(file).ReadAsArray()\n",
    "    drought = np.where(np.subtract(rainarr,psrc) < 0,1,0)\n",
    "    drought_arr.append(drought)\n",
    "    arrToRast(drought, 0.05, display = True)\n",
    "    \n",
    "os.chdir(cwd) \n",
    "del rainarr, drought"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
